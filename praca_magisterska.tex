\documentclass{mini}

\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{tikz-qtree}

\usetikzlibrary{calc, shapes, backgrounds, arrows, positioning, calc}

\definecolor{mojkolor}{rgb}{0.99, 1, 0.99}

%------------------------------------------------------------------------------%
\title{Statystyczne metody regresji porządkowej}
\author{Marta Sommer}
\tytsupervisor{prof. nzw. dr hab.}
\supervisor{Przemysław Grzegorzewski}
\type{magisters}
\discipline{matematyka}
\monthyear{czerwiec 2015}
\date{\today}
\album{237503}
%------------------------------------------------------------------------------%

\begin{document}
\maketitle
\tableofcontents

\chapter*{Wstęp}

Regresja porządkowa (ang. \textit{ordinal regression}) jest jednym z działów uczenia maszynowego. Od problemu klasycznej regresji różni ją to, że zmienna odpowiedzi jest dyskretna, natomiast od problemu klasyfikacji to, że zmienna odpowiedzi ma pewien naturalny porządek. Regresja porządkowa zajmuje się zatem uczeniem i oceną jakości predyktora, który modeluje zmienną uporządkowaną i skończoną. Problem regresji porządkowej rozwija się dość szybko m.in. dlatego, że ma on bardzo wiele zastosowań, choćby w systemach rekomendacji, czy bardzo popularnych wyszukiwarkach internetowych. Prześledźmy to na konkretnym przykładzie. Wyobraźmy sobie sytuację, że chcielibyśmy określić, w jakim stopniu danemu człowiekowi spodoba się sprzedawany przez nas produkt. Mamy do dyspozycji zbiór treningowy składający się z wektora zmiennej objaśniającej $\textbf{x}=(x_1, \ldots, x_d)$, gdzie $x_i$ są różnymi cechami określającymi daną osobę (np. płeć, wiek, wykształcenie, ...). Cechy te -- podobnie jak w przypadku zwykłej regresji -- mogą być zarówno ciągłe, jak i dyskretne. Mamy również dostęp do zmiennej objaśnianej $\textbf{y}=(y_1, \ldots, y_r)$, będącej wektorem zero-jedynkowym, wskazującym która klasa została przypisana danemu rekordowi. W naszym przykładzie, zmienną odpowiedzi mogłyby być na przykład: \textit{zdecydowanie mi się nie podoba}, \textit{nie podoba mi się}, \textit{nie mam zdania}, \textit{podoba mi się}, \textit{zdecydowanie mi się podoba}. Widać wyraźnie, że są one uporządkowane.

Najprostszym podejściem do tego typu problemu byłoby zignorowanie kolejności zmiennej odpowiedzi i potraktowanie go, jak zwykłą klasyfikację. W takim przypadku tracimy jednak pewną informację, która prawdopodobnie mogłaby przyczynić się do poprawy naszego klasyfikatora. Idąc w drugą stronę, można potraktować nasz problem, jak zwykłą regresję, zamieniając zmienną odpowiedzi na pewną zmienną ciągłą i to ją modelując, a następnie z powrotem dyskretyzować. Pojawia się tu jednak problem, jak optymalnie zrobić taką transformację, uwzględniając chociażby fakt, że nasza odpowiedź niekoniecznie jest monotoniczna (tzn. np. różnica między \textit{nie podoba mi się} a \textit{nie mam zdania} wcale mnie musi być taka sama, jak między \textit{podoba mi się} a \textit{zdecydowanie mi się podoba}). 

Możemy wyróżnić dwa główne nurty w regresji porządkowej:
\begin{itemize}
	\item prognoza konkretnej obserwacji (nacisk kładziony jest tu na wyznaczenie konkretnego $\textbf{y}$ dla konkretnego $\textbf{x}$ np. czy potencjalnemu klientowi spodoba się dany produkt),
	\item uszeregowanie kilku obserwacji (celem nie jest poznanie estymacji konkretnej zmiennej odpowiedzi, ale takie uszeregowanie kilku rekordów, by te najbardziej preferowane znalazły się na samej górze, a te najmniej na samym dole np. w jakiej kolejności powinny wyświetlić się znalezione strony w wyszukiwarce). 
\end{itemize}

W mojej pracy zajmować się będę przede wszystkim pierwszym punktem, lecz nakreślę też kilka podejść dotyczących drugiego. 


\chapter{Opis teoretyczny dostepnych metod}

W tym rozdziale opracuję kilka znanych i opisanych w literaturze podejść do regresji porządkowej. Można je podzielić na kilka grup:
\begin{itemize}
	\item korzystające z dostępnych metod klasyfikacji, m.in.:
		\begin{itemize}
			\item metoda zaproponowana przez E. Franka i M. Halla,
		\end{itemize}
	\item modyfikujące dostępne metody klasyfikacji, m.in.:
		\begin{itemize}
			\item SVM,
			\item sieci neuronowe,
			\item procesy gaussowskie,
		\end{itemize}
	\item metody stworzone specjalnie dla regresji porząckowej, m.in.:
		\begin{itemize}
			\item model proporcjonalnych szans.
		\end{itemize}
\end{itemize}  

\section{Metoda zaproponowana przez E. Franka i M. Halla}

Podejście Franka i Halla (por. \cite{fh}) do zagadnienia regresji porządkowej opiera się nie na stworzeniu nowego modelu, ale na odpowiednim przedefiniowaniu zbioru danych, a następnie na sprowadzeniu zadania do problemu zwykłej klasyfikacji z dwoma klasami. Przekształcamy zatem $r$--klasowy model regresji porządkowej do $(r-1)$ dwuklasowych problemów klasyfikacji. 

Na wejściu otrzymujemy $n$ par $(\textbf{x},y)$, gdzie $\textbf{x} = (x_1, \ldots, x_K)^T$ jest wektorem cech, a $y \in \lbrace y_1, \ldots, y_r \rbrace$ reprezentuje klasę, do której należy dana obserwacja. Zakładamy rosnący porządek na zbiorze $\lbrace y_1, \ldots, y_r \rbrace$, tzn. $y_1 \prec \ldots \prec y_r$. Algorytm do budowy modelu wygląda następująco:

\begin{enumerate}
\item Modyfikujemy zbiór uczący (otrzymując $r-1$ nowych zbiorów uczących).
\item Dla każdego nowo uzyskanego zbioru danych dopasowujemy zwykły model klasyfikacyjny (np. drzewo) taki, który zwraca prawdopodobieństwa przynależności do klas.
\item Robimy predykcję dla nowej obserwacji. 
\end{enumerate}

\begin{figure}[h]
\begin{center}
	\begin{tikzpicture}
		\node(gora) {\begin{tabular}{c|c}
					$\mathcal{X}$ & $\mathcal{Y}$ \\
					[1ex] \hline \\ [-1.5ex] 
					$x_1^{(1)}$ $\ldots$ $x_K^{(1)}$ & $y_1$ \\
					[1ex] $x_1^{(2)}$ $\ldots$ $x_K^{(2)}$ & $y_r$ \\
					[1ex] \vdots & $\vdots$ \\
					[1ex] $x_1^{(n)}$ $\ldots$ $x_K^{(n)}$ & $y_2$\\
				\end{tabular}};
		\node [below= 4cm of gora] (srodek) {$\ldots$};
		\node [right= 3cm of srodek] (prawo) {\begin{tabular}{c|c}
					$\mathcal{X}$ & $\mathcal{Y}^{(r-1)}$ \\
					[1ex] \hline \\ [-1.5ex] 
					$x_1^{(1)}$ $\ldots$ $x_K^{(1)}$ & $0$ \\
					[1ex] $x_1^{(2)}$ $\ldots$ $x_K^{(2)}$ & $1$ \\
					[1ex] \vdots & $\vdots$ \\
					[1ex] $x_1^{(n)}$ $\ldots$ $x_K^{(n)}$ & $0$\\
				\end{tabular}};
		\node [left= 3cm of srodek] (lewo) {\begin{tabular}{c|c}
					$\mathcal{X}$ & $\mathcal{Y}^{(1)}$ \\
					[1ex] \hline \\ [-1.5ex] 
					$x_1^{(1)}$ $\ldots$ $x_K^{(1)}$ & $0$ \\
					[1ex] $x_1^{(2)}$ $\ldots$ $x_K^{(2)}$ & $1$ \\
					[1ex] \vdots & $\vdots$ \\
					[1ex] $x_1^{(n)}$ $\ldots$ $x_K^{(n)}$ & $1$\\
				\end{tabular}};
		\path[draw, -latex',thick] (gora) -- (lewo);
		\path[draw, -latex',thick] (gora) -- (prawo);
	\end{tikzpicture}
\end{center}
\caption{Modyfikacja przykładowego zbioru uczącego.}
\end{figure}

\underline{Ad. $1)$}

Chcemy otrzymać $r-1$ nowych zbiorów o zero-jedynkowej zmiennej odpowiedzi. W jaki sposób to zrobić?
Macierz atrybutów pozostaje bez zmian, zmienia się jedynie wektor zmiennej odpowiedzi według zasady:
\begin{eqnarray*}
y_i^{(1)} &=& \mathbb{I}\lbrace y_i>y_1 \rbrace\\
&\vdots& \\
y_i^{(r-1)} &=& \mathbb{I}\lbrace y_i>y_{r-1} \rbrace\\
\end{eqnarray*}

\underline{Ad. $3)$}

Dla nowego wektora atrybutów $\textbf{x}$ robimy predykcję na $r-1$ modelach uzyskanych w punkcie $2)$. Zwracamy jednak nie predykcję klasy, ale prawdopodobieństwo przynależności do klasy pierwszej. Uzyskujemy w ten sposób $r-1$ następuących prawdopodobieństw:
\begin{eqnarray*}
\mathbb{P}(y &>& y_{1})\\
&\vdots& \\
\mathbb{P}(y &>& y_{r-1}).\\
\end{eqnarray*}

Nas natomiast interesują prawdopodobieństwa:
\begin{eqnarray*}
\mathbb{P}(y &=& y_{1})\\
&\vdots& \\
\mathbb{P}(y &=& y_{r-1}).\\
\end{eqnarray*}

Łatwo otrzymamy korzystając z następującego wzoru łańcuchowego:
\begin{eqnarray*}
\mathbb{P}(y = y_{1}) &=& 1 - \mathbb{P}(y > y_{1})\\
&\vdots& \\
\mathbb{P}(y = y_{i}) &=& \mathbb{P}(y > y_{i-1}) - \mathbb{P}(y > y_{i}) \qquad \text{dla}\hspace{5mm} i=2, \ldots, r-1\\
&\vdots& \\
\mathbb{P}(y = y_{r}) &=& \mathbb{P}(y = y_{r-1}).\\
\end{eqnarray*}

Ostatecznie, nowej obserwacji przypisujemy klasę, której prawdopodobieństwo ($\mathbb{P}(y=y_i)$) było największe.




\section{Sieci neuronowe}

Sieci neuronowe to bardzo proste i szeroko stosowane narzędzie zarówno w problemach regresji, jaki i klasyfikacji. Znalazło ono również swoje zastosowanie w regresji porządkowej (por. \cite{nna}). 

Standardowo, na wejściu otrzymujemy zbiór uczący w postaci $n$ par $(\textbf{x},\textbf{y})$, gdzie $\textbf{x} = (x_1, \ldots, x_K)^T$ jest wektorem cech, a $\textbf{y} = (y_1, \ldots, y_r)^T$ wektorem zero-jedynkowym reprezentującym klasę, do której należy dana obserwacja. Zakładamy rosnący porządek na zbiorze $\lbrace y_1, \ldots, y_r \rbrace$, tzn. $y_1 \prec \ldots \prec y_r$.

W przeciwieństwie do zwykłej klasyfikacji, nasza sieć neuronowa będzie zakładać porządek zmiennej odpowiedzi. W jaki sposób? Podobnie, jak w metodzie proporcjonalnych szans, jako wektor wyjściowy, zamiast wektora $\textbf{y} = (0, 0, \ldots, 1, \ldots, 0)^T$, mającego jedynkę na $i$--tym miejscu, jeśli obserwacja należała do $i$--tej klasy, rozważać będziemy wektor $\textbf{y} = (1, 1, \ldots, 1, \ldots, 0)^T$, mający jedynki na miejscach od pierwszego do $i$--tego.

Otrzymujemy w ten sposób sieć neuronową o $K$ neuronach w warstwie wejściowej, z których każdy reprezentuje inną cechę z wektora $\textbf{x}$, jednej (bądź więcej) warstwie ukrytej o $m$ neuronach i warstwie wyjściowej zawierającej $r$ neuronów, które reprezentują odpowiedź $\textbf{y}$ w formie opisanej powyżej. Za funkcję przejścia przyjmiemy funkcję sigmoidalną $f(x) = \frac{1}{1+e^{-x}}$, dobrze reprezentującą przynależność do danej klasy jako prawdopodobieństwo. Może się zdarzyć, że wyjściowy wektor nie będzie ciągiem malejącym (co przeczył intuicji), jednak nie jest to konieczne do robienia predykcji. 

\begin{figure}[h]
\begin{center}

	\def\layersep{6cm}

\begin{tikzpicture}[shorten >=1pt, ->, draw=black!50, node distance=\layersep]
    \tikzstyle{neuron}=[circle, fill=black!25, minimum size=17pt, inner sep=0pt]
    \tikzstyle{input neuron}=[neuron, fill=green!50];
    \tikzstyle{output neuron}=[neuron, fill=red!50];
    \tikzstyle{hidden neuron}=[neuron, fill=blue!50];
    \tikzstyle{annot} = [text width=5em, text centered]

    \foreach \name / \y in {1/1,K/3}
        \node[input neuron] (I-\y) at (0,-3*\y) {$\text{wyjscie}^{(0)}_\name$};
    \node[draw=none, scale=4, text height=0.333cm] (I-2) at (0,-3*2) {$\vdots$};

	\foreach \name / \y in {1/1, 2/2, m/4}
        \path[yshift=1.4cm]
            node[hidden neuron] (H-\y) at (\layersep,-3*\y cm) {$\text{wyjscie}^{(1)}_{\name}$};
    \path[yshift=1.4cm]
            node[draw=none, scale=4, text height=0.333cm] (H-3) at (\layersep,-3*3 cm) {$\vdots$};

	\foreach \name / \y in {1/1, r/3}
        \path[yshift=0cm]
            node[output neuron] (O-\y) at (2*\layersep,-3*\y cm) {$\text{wyjscie}^{(2)}_{\name}$};
    \path[yshift=0cm]
            node[draw=none, scale=4, text height=0.333cm] (O-2) at (2*\layersep,-3*2 cm) {$\vdots$};

	\foreach \source / \sname in {1/1,3/K}
        \foreach \dest / \dname in {1/1,2/2,4/m}
            \path (I-\source) edge node[pos=0.25, sloped, fill=mojkolor, opacity=0.9, text opacity=1]{$w_{\sname\rightarrow\dname}^{(1)}$} (H-\dest);
    \foreach \source / \sname in {1/1,2/2,4/m}
    	\foreach \dest / \dname in {1/1,3/r}
        \path (H-\source) edge node[pos=0.75, sloped, fill=mojkolor, opacity=0.9, text opacity=1]{$w_{\sname\rightarrow\dname}^{(2)}$} (O-\dest);
        
    \node[annot,above of=H-1, node distance=1.5cm] (hl) {Warstwa ukryta};
    \node[annot,left of=hl] {Warstwa wejściowa};
    \node[annot,right of=hl] {Warstwa wyjściowa};

\end{tikzpicture}
\end{center}
\caption{Przykładowa sieć neuronowa.}
\end{figure}

Uczenie sieci neuronowej będzie się odbywało algorytmem propagacji wstecznej z kwadratową funkcją straty (można też użyć jakiejś innej np. entropii). Algorytm wygląda następująco:
\begin{enumerate}
\item Wybieramy małe wagi początkowe oraz niewielki współczynnik $\eta>0$.
\item Losujemy parę $(\textbf{x},\textbf{y})$ ze zbioru uczącego.
\item Przebiegamy sieć w przód.
\item Przebiegamy sieć w tył (licząc błąd dla każdego neuronu).
\item Zmieniamy wagi.
\item Dopóki nie osiągniemy zadowalająco niskiego błędu, wracamy do punktu $2)$.
\end{enumerate} 

\underline{Ad. $3)$} 

Dla każdego neuronu obliczamy wartość wejściową ze wzoru:
$$
wejscie_j^{(i)} = \sum_{k:\hspace{2mm}\exists\hspace{2mm} w^{(i)}_{k\rightarrow j}} \left( w^{(i)}_{k\rightarrow j}\cdot wyjscie_k^{(i-1)} \right),
$$
gdzie $wyjscie_i^{(0)} = x_i$. A następnie wyjściową:
$$
wyjscie_j^{(i)} = f\left(wyjscie_j^{(i)}\right). 
$$

\underline{Ad. $4)$}

Dla warstwy wyjściowej błąd ma postać:
$$
\delta_j = -2\cdot wyjscie_j^2\cdot \left( 1- wyjscie_j \right)^2\cdot(y_j - wyjscie_j),
$$
zaś dla warstw ukrytych:
$$
\delta_j^{(i)} =  wyjscie_j^{(i)}\cdot \left( 1- wyjscie_j^{(i)} \right) \cdot \sum_{k:\hspace{2mm}\exists\hspace{2mm} w^{(i+1)}_{j\rightarrow k}} \left( w^{(i+1)}_{j\rightarrow k}\cdot \delta_k^{(i-1)} \right).
$$

\underline{Ad. $5)$}

Modyfikacja wag przebiega następująco:
$$
w_{k\rightarrow j}^{(i)^{(new)}} = w_{k\rightarrow j}^{(i)^{(old)}} - \eta\cdot\delta_j^{(i)}\cdot wyjscie^{(i-1)}_k.
$$

Predykcja opiera się już tylko na przejściu algorytmu w przód z nowymi obserwacjami wejściowymi $\textbf{x}$ i ustaleniu progu (najczęściej równego $0,5$), klasyfikującego neuron wyjściowy jako jedynkę. Skanujemy wektor wyjściowy zaczynając od $y_1$ i kończymy, gdy pierwszy raz natkniemy się na $0$. Przypisujemy obserwacji taką klasę, ile wynosił znaleziony przez nas ciąg jedynek.



%-----------------------------------------------------------------------------%

\begin{thebibliography}{9}
	\bibitem{fh} Frank E., Hall M., A simple approach to ordinal classification, \emph{Proceedings of the European Conference on Machine Learning}, Freibourg, Niemcy, 2001, str. 146--156.
	\bibitem{nna} Cheng J., Wang Z., Pollastri G., A neural network approach to ordinal regression, \emph{Neutral Networks}, Hong Kong, 2008.
\end{thebibliography}

%-----------------------------------------------------------------------------%

\makestatement
\end{document}
