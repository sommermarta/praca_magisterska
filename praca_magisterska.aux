\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{plplain}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Wst\IeC {\k e}p}{5}{section*.1}}
\citation{pom}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Opis teoretyczny dost\IeC {\k e}pnych metod}{7}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Postawienie problemu i podstawowe oznaczenia}{7}{section.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Model proporcjonalnych szans}{7}{section.1.2}}
\citation{koronacki}
\citation{pom}
\citation{svm}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Wektory maszyn podpieraj\IeC {\k a}cych (SVM)}{8}{section.1.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Przyk\IeC {\l }adowe rozdzielenie klas metod\IeC {\k a} SVM. W przypadku nieseparowalnym dok\IeC {\l }adamy kar\IeC {\k e}, b\IeC {\k e}d\IeC {\k a}c\IeC {\k a} odleg\IeC {\l }o\IeC {\'s}ci\IeC {\k a} \IeC {\'z}le zaklasyfikowanej obserwacji od odpowiedniego marginesu.\relax }}{9}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{svm1}{{1.1}{9}{Przykładowe rozdzielenie klas metodą SVM. W przypadku nieseparowalnym dokładamy karę, będącą odległością źle zaklasyfikowanej obserwacji od odpowiedniego marginesu.\relax }{figure.caption.2}{}}
\citation{nna}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Przyk\IeC {\l }adowa klasyfikacja metod\IeC {\k a} SVM.\relax }}{10}{figure.caption.3}}
\newlabel{svm}{{1.2}{10}{Przykładowa klasyfikacja metodą SVM.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Sieci neuronowe}{11}{section.1.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Przyk\IeC {\l }adowa sie\IeC {\'c} neuronowa.\relax }}{12}{figure.caption.4}}
\newlabel{siec}{{1.3}{12}{Przykładowa sieć neuronowa.\relax }{figure.caption.4}{}}
\citation{fh}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Metoda Franka i Halla}{13}{section.1.5}}
\citation{reg}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Modyfikacja przyk\IeC {\l }adowego zbioru ucz\IeC {\k a}cego.\relax }}{14}{figure.caption.5}}
\newlabel{fh}{{1.4}{14}{Modyfikacja przykładowego zbioru uczącego.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Procesy gaussowskie}{14}{section.1.6}}
\newlabel{apriori}{{1.1}{15}{Procesy gaussowskie}{equation.1.6.1}{}}
\newlabel{calka1}{{1.2}{15}{Procesy gaussowskie}{equation.1.6.2}{}}
\newlabel{calka2}{{1.3}{15}{Procesy gaussowskie}{equation.1.6.3}{}}
\newlabel{calka21}{{1.4}{15}{Procesy gaussowskie}{equation.1.6.4}{}}
\newlabel{bayes}{{1.5}{16}{Procesy gaussowskie}{equation.1.6.5}{}}
\newlabel{prod}{{1.6}{16}{Procesy gaussowskie}{equation.1.6.6}{}}
\newlabel{dystryb}{{1.7}{16}{Procesy gaussowskie}{equation.1.6.7}{}}
\citation{reg}
\newlabel{calka22}{{1.8}{17}{Procesy gaussowskie}{equation.1.6.8}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Diagnostyka modelu}{19}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Procent poprawnej klasyfikacji}{19}{section.2.1}}
\newlabel{dop1}{{2.1}{19}{Procent poprawnej klasyfikacji}{equation.2.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}\IeC {\'S}redni b\IeC {\l }\IeC {\k a}d bezwzgl\IeC {\k e}dny}{20}{section.2.2}}
\newlabel{dop2}{{2.2}{20}{Średni błąd bezwzględny}{equation.2.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Krzywa ROC w przypadku dwuklasowym}{20}{section.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Tabela jako\IeC {\'s}ci dopasowania. TP (ang. \textit  {True Positives}) to liczba rekord\IeC {\'o}w z klasy pozytywnej, kt\IeC {\'o}re zosta\IeC {\l }y zakwalifikowane przez nas jako klasa pozytywna. Analogicznie, TN (ang. \textit  {True Negatives}) to liczba rekord\IeC {\'o}w z klasy negatywnej, kt\IeC {\'o}re zostaly zakwalifikowane przez nas jako klasa negatywna. FP (ang. \textit  {False Positives}) oznacza rekordy z klasy negatywnej, zakwalifikowane jako klasa pozytywna i wreszcie, FN (ang. \textit  {False Negatives}) to rekordy z klasy pozytywnej, kt\IeC {\'o}re b\IeC {\l }\IeC {\k e}dnie zakwalifikowane zosta\IeC {\l }y jako klasa negatywna.\relax }}{20}{figure.caption.6}}
\newlabel{tabeladopasowania}{{2.1}{20}{Tabela jakości dopasowania. TP (ang. \textit {True Positives}) to liczba rekordów z klasy pozytywnej, które zostały zakwalifikowane przez nas jako klasa pozytywna. Analogicznie, TN (ang. \textit {True Negatives}) to liczba rekordów z klasy negatywnej, które zostaly zakwalifikowane przez nas jako klasa negatywna. FP (ang. \textit {False Positives}) oznacza rekordy z klasy negatywnej, zakwalifikowane jako klasa pozytywna i wreszcie, FN (ang. \textit {False Negatives}) to rekordy z klasy pozytywnej, które błędnie zakwalifikowane zostały jako klasa negatywna.\relax }{figure.caption.6}{}}
\newlabel{fig:f11}{{2.2a}{21}{Duże TPR, ale małe TNR.\relax }{figure.caption.7}{}}
\newlabel{sub@fig:f11}{{a}{21}{Duże TPR, ale małe TNR.\relax }{figure.caption.7}{}}
\newlabel{fig:f22}{{2.2b}{21}{Zrównoważone TPR i TNR.\relax }{figure.caption.7}{}}
\newlabel{sub@fig:f22}{{b}{21}{Zrównoważone TPR i TNR.\relax }{figure.caption.7}{}}
\newlabel{fig:f22}{{2.2c}{21}{Małe TPR, ale duże TNR.\relax }{figure.caption.7}{}}
\newlabel{sub@fig:f22}{{c}{21}{Małe TPR, ale duże TNR.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Spos\IeC {\'o}b konstruowania krzywej ROC w przypadku dwuklasowym.\relax }}{21}{figure.caption.7}}
\newlabel{wszystkietrzy}{{2.2}{21}{Sposób konstruowania krzywej ROC w przypadku dwuklasowym.\relax }{figure.caption.7}{}}
\newlabel{fig:f1}{{2.3a}{22}{Standardowy sposób rysowania krzywej ROC.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:f1}{{a}{22}{Standardowy sposób rysowania krzywej ROC.\relax }{figure.caption.8}{}}
\newlabel{fig:f2}{{2.3b}{22}{Krzywa ROC z TNR (zamiast FPR) na osi OX.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:f2}{{b}{22}{Krzywa ROC z TNR (zamiast FPR) na osi OX.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Przyk\IeC {\l }adowe krzywe ROC.\relax }}{22}{figure.caption.8}}
\newlabel{krzyweroc}{{2.3}{22}{Przykładowe krzywe ROC.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Krzywa ROC w przypadku regresji porz\IeC {\k a}dkowej}{23}{section.2.4}}
\citation{roc1}
\citation{roc2}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Spos\IeC {\'o}b konstruowania krzywej ROC w przypadku trzyklasowym.\relax }}{24}{figure.caption.9}}
\newlabel{trzyklasowy}{{2.4}{24}{Sposób konstruowania krzywej ROC w przypadku trzyklasowym.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Wsp\IeC {\'o}\IeC {\l }czynnik VUS}{24}{section.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Krzywa ROC w przypadku trzyklasowym.\relax }}{25}{figure.caption.10}}
\newlabel{3d}{{2.5}{25}{Krzywa ROC w przypadku trzyklasowym.\relax }{figure.caption.10}{}}
\newlabel{dop3}{{2.3}{25}{Współczynnik VUS}{equation.2.5.3}{}}
\citation{zbiorki}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Por\IeC {\'o}wnanie metod modelowania i wsp\IeC {\'o}\IeC {\l }czynnik\IeC {\'o}w diagnostycznych}{27}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Opis danych}{27}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Analiza wynik\IeC {\'o}w}{27}{section.3.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Rozk\IeC {\l }ady odpowiedzi poszczeg\IeC {\'o}lnych zbior\IeC {\'o}w danych.\relax }}{28}{figure.caption.11}}
\newlabel{rozkladdanych}{{3.1}{28}{Rozkłady odpowiedzi poszczególnych zbiorów danych.\relax }{figure.caption.11}{}}
\newlabel{vus01}{{3.2a}{29}{Przypadek, w którym źle sklasyfikowana jest tylko jedna obserwacja. Zamiast klasy nr $5$, została przyporządkowana klasa nr $1$.\relax }{figure.caption.13}{}}
\newlabel{sub@vus01}{{a}{29}{Przypadek, w którym źle sklasyfikowana jest tylko jedna obserwacja. Zamiast klasy nr $5$, została przyporządkowana klasa nr $1$.\relax }{figure.caption.13}{}}
\newlabel{vus02}{{3.2b}{29}{Przypadek, w którym źle sklasyfikowana jest tylko jedna obserwacja. Zamiast klasy nr $5$, została przyporządkowana klasa nr $4$.\relax }{figure.caption.13}{}}
\newlabel{sub@vus02}{{b}{29}{Przypadek, w którym źle sklasyfikowana jest tylko jedna obserwacja. Zamiast klasy nr $5$, została przyporządkowana klasa nr $4$.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Tabele pokazuj\IeC {\k a} przyk\IeC {\l }adowe zbiory testowe. W kolumnach przedstawione s\IeC {\k a} kolejne obserwacje. $y$ reprezentuje prawdziw\IeC {\k a} klas\IeC {\k e}, a $\mathaccentV {hat}05E{y}$ oszacowan\IeC {\k a} przez nas klas\IeC {\k e} na podstawie warto\IeC {\'s}ci funkcji rzeczywistej $f$. Nast\IeC {\k e}pnie kolumny tabeli s\IeC {\k a} sortowane wed\IeC {\l }ug warto\IeC {\'s}ci tej funkcji.\relax }}{29}{figure.caption.13}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Wyznaczanie wsp\IeC {\'o}\IeC {\l }czynnika SB\relax }}{30}{algorithm.1}}
\newlabel{algo:bubble_sort}{{1}{30}{Wyznaczanie współczynnika SB\relax }{algorithm.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Tabela wynik\IeC {\'o}w. Na czerwono zaznaczony jest najlepszy wynik dla ka\IeC {\.z}dego wska\IeC {\'z}nika ka\IeC {\.z}dego zbioru. Dla sieci neuronowych nie da si\IeC {\k e} niestety obliczy\IeC {\'c} wsp\IeC {\'o}\IeC {\l }czynnika VUS ani SB.\relax }}{32}{table.caption.15}}
\newlabel{wyniki}{{3.1}{32}{Tabela wyników. Na czerwono zaznaczony jest najlepszy wynik dla każdego wskaźnika każdego zbioru. Dla sieci neuronowych nie da się niestety obliczyć współczynnika VUS ani SB.\relax }{table.caption.15}{}}
\@writefile{toc}{\contentsline {chapter}{Podsumowanie}{33}{section*.17}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Wyprowadzenia pomocniczych twierdze\IeC {\'n}}{35}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Wz\IeC {\'o}r Bayesa dla wi\IeC {\k e}cej ni\IeC {\.z} jednego warunku}{35}{section.A.1}}
\newlabel{app1}{{A.1}{35}{Wzór Bayesa dla więcej niż jednego warunku}{section.A.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.2}Ca\IeC {\l }ka z iloczynu dystrybuanty i g\IeC {\k e}sto\IeC {\'s}ci rozk\IeC {\l }adu normalnego}{35}{section.A.2}}
\newlabel{app2}{{A.2}{35}{Całka z iloczynu dystrybuanty i gęstości rozkładu normalnego}{section.A.2}{}}
\bibcite{fkaj}{1}
\bibcite{nna}{2}
\bibcite{zbiorki}{3}
\bibcite{reg}{4}
\bibcite{svm}{5}
\bibcite{af}{6}
\bibcite{zbioasdgrki}{7}
\bibcite{pom}{8}
\bibcite{reg2}{9}
\bibcite{reg3}{10}
\bibcite{fh}{11}
\bibcite{koronacki}{12}
\bibcite{roc2}{13}
\bibcite{reg4}{14}
\bibcite{zbiorki2}{15}
\bibcite{roc1}{16}
\@writefile{toc}{\contentsline {chapter}{Literatura}{37}{section*.18}}
